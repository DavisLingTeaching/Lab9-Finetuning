{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-nn-1G02YK3"
   },
   "source": [
    "# Lab 9: Finetuning BERT-based models\n",
    "\n",
    "In this lab, we will explore finetuning a BERT model for classification. Your task will be to classify movie reviews as positive or negative (i.e. the task from HW2). Supporting code will help you with the actual training. Your job is to focus on formatting the input and evaluating the accuracy of your final model.\n",
    "\n",
    "Once you finish working on this lab, please download it as a .ipynb notebook and submit the notebook to Moodle.\n",
    "\n",
    "#### **What should I do if I run out of RAM?**\n",
    "\n",
    "The free GPUs that Colab assigns might not always reliable. Sometimes you code will run without issues, and other times you might run into RAM errors. For this reason, try to train your models on as much data as possible, but do not worry if you are not able to train it on all of the data. You can also try to run the models on your personal computers without using GPUs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0U2TkED2XFD"
   },
   "source": [
    "\n",
    "### Guiding Questions\n",
    "\n",
    "1. How do we use pretrained transformer models?\n",
    "1. How do we finetune a neural model of language for classification?\n",
    "\n",
    "### Learning Objectives.\n",
    "\n",
    "1. Understand how to map classification to the context of transformers\n",
    "1. Hands on experience using pretrained models\n",
    "1. Build a classifer on top of a pretrained model\n",
    "1. Reason about your model and its abilities\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Question | Points |\n",
    "| ------| ----- |\n",
    "| load_data | 25 Points |\n",
    "| Reflection | 75 Points |\n",
    "\n",
    "### Deadline:\n",
    "\n",
    "November 12, 11PM EST\n",
    "\n",
    "### Submission format:\n",
    "ipynb file saved after running your code cells and submitted to Moodle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U33GNX-4AyWV"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ9NSOjHAyWW"
   },
   "source": [
    "We will use HuggingFace throughout this lab. Finetuning involves XX steps:\n",
    "\n",
    "1. Loading a pretrained model\n",
    "2. Loading our finetuning data\n",
    "3. Searching for good hyperparameters for our model\n",
    "4. Training our model\n",
    "5. Testing our model\n",
    "6. Saving our model\n",
    "\n",
    "HuggingFace comes with tools for doing all of these. I will give very brief overviews of them below and point you to their code base. This will be useful for at least some of your final projects, so please look over these materials on your own.\n",
    "\n",
    "### The model and the tokenizer\n",
    "\n",
    "HuggingFace hosts a large number of pretrained models. You can find them [here](https://huggingface.co/). The main library for working with these models is transformers (documentation [link](https://huggingface.co/docs/transformers/index)). Each model comes with a tokenizer which maps from words to ids for the relevant model.\n",
    "\n",
    "### The data format\n",
    "\n",
    "In order to finetune our model with HuggingFace we need our data formatted in a particular way. We will use their dataset library (documentation [link](https://huggingface.co/docs/datasets/index)). Consider the following (modified) sample from the movie review dataset we are using:\n",
    "\n",
    "    [{'text': 'Note that I did not say that it is',\n",
    "        'label': 0},\n",
    "    {'text': 'In what is arguably the best outdoor adventure film of all time,\n",
    "        four city guys confront nature\\'s wrath, in a story of survival.'  \n",
    "        'label': 1}]\n",
    "\n",
    "Notice that it is a list of dictionaries mapping text to their labels. You will write a data loader that does this step.\n",
    "\n",
    "### Hyperparameter search with Trainer\n",
    "\n",
    "Recalling, HW2 one thing we have to do is find good hyperparameters. Luckily, there exists libraries that facilitate this. We will use [optuna](https://optuna.org/) coupled with HuggingFace's libraries to find optimal hyperparameters for our model.\n",
    "\n",
    "### Training with Trainer\n",
    "\n",
    "To finetune our model, we need a way of training the model. HuggingFace has a utility called [Trainer](https://huggingface.co/docs/evaluate/main/en/transformers_integrations#trainer) that will handle this for us.\n",
    "\n",
    "### Testing with Evaluate\n",
    "\n",
    "Finally, we need to evaluate our model to see if it is any good. You've already done your own accuracy, precision, recall, and F1-scores before. Here will make use of HuggingFace's [Evaluate](https://huggingface.co/docs/evaluate/main/en/index) library to do the hard things for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KVFIsJCAyWW"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ivsLMhkAyWW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: transformers in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: datasets in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: accelerate in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: evaluate in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (0.4.1)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (1.12.1)\n",
      "Requirement already satisfied: colorlog in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (2.0.23)\n",
      "Requirement already satisfied: tqdm in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: psutil in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: six in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: Mako in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests->transformers)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna transformers datasets accelerate evaluate gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "enEQBIsfAyWW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/forrestdavis/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch, evaluate, accelerate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import glob\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_dataset\n",
    "import optuna\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1QaKuu8QAyWX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device depending on whether or not you have access to GPUs\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k3M3VMTAyWX"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "orqPhWm8AyWX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "modelname = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelname,\n",
    "                                                            num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfH-_W9-AyWX"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Foqv8n-gM8_O"
   },
   "outputs": [],
   "source": [
    "!gdown 18iyGEGz4csxVDUee5gqUafbmvovUBzvr\n",
    "!unzip -o sentiment_data.zip\n",
    "!rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8jBpehuAyWY"
   },
   "outputs": [],
   "source": [
    "#TODO: 25pts\n",
    "def load_data(path: str, label2id: dict) -> list[dict]:\n",
    "    \"\"\" Loads movie review data into a dictionary\n",
    "    Args:\n",
    "        path (str): Path to sentiment data directory\n",
    "                    (e.g., sentiment_data)\n",
    "        label2id (dict): Dict mapping label (i.e. pos, neg)\n",
    "                        to numbers (e.g., {'pos': 0, 'neg': 1})\n",
    "    Returns:\n",
    "        data (list[dict]): List of dictionaries, see the markdown block above\n",
    "                            this cell.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doIXxb6hAyWY"
   },
   "outputs": [],
   "source": [
    "def getDataset(path: str, label2id: dict,\n",
    "               tokenizer:AutoTokenizer=None,\n",
    "              tokenize:bool=True,\n",
    "               percent:float = 0.25) -> Dataset:\n",
    "    \"\"\" Return HuggingFace Dataset instance\n",
    "    Args:\n",
    "        path (str): path to directory\n",
    "        label2id (dict): Dictionary mapping classification labels to id\n",
    "        tokenizer (AutoTokenizer): A HuggingFace pre-trained tokenizer\n",
    "        tokenize (bool): Whether to tokenize data. Default True\n",
    "    Returns:\n",
    "        (Dataset): HuggingFace Dataset instance\n",
    "    \"\"\"\n",
    "    data = load_data(path, label2id)\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "    data = data[:int(len(data)*percent)]\n",
    "    data = Dataset.from_list(data)\n",
    "    # Tokenize\n",
    "    if tokenize:\n",
    "        if tokenizer is None:\n",
    "            print('Pass a tokenizer')\n",
    "            return\n",
    "        data = data.map(lambda examples: tokenizer(examples[\"text\"],\n",
    "                                                   return_tensors=\"pt\",\n",
    "                                                   padding=True, truncation=True),\n",
    "                        batched=True).with_format(\"torch\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-zWhm8_AyWY"
   },
   "outputs": [],
   "source": [
    "train_small_dataset = getDataset(\"sentiment_data/train\", {\"pos\": 0, \"neg\": 1}, tokenizer, percent=0.05)\n",
    "train_dataset = getDataset(\"sentiment_data/train\", {\"pos\": 0, \"neg\": 1}, tokenizer, percent=0.25)\n",
    "eval_dataset = getDataset(\"sentiment_data/eval\", {\"pos\": 0, \"neg\": 1}, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sohXRw4NAyWY"
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeUXJVHIAyWY"
   },
   "source": [
    "Recall from HW2 that models involve hyperparameters. We often want to find optimal hyperparameters that will result in better models. We can automate this process using HuggingFace. What will need to do is install a hyperparameter optimization library. We will use [optuna](https://optuna.org/).\n",
    "\n",
    "At its core, hyperparameter optimization is about trying different configurations and comparing model performance. To facilitate this we will need a way of reseting our model so we can try new hyperparameters. The model_init function below does just that. Additionally, we will want to sample a smaller amount of data, since tuning can take a long time! The code below creates a set up that does this. Look over the code and make sure you understand its aims!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD0ux0L3AyWY"
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(modelname, num_labels=2).to(device)\n",
    "\n",
    "# Uses accuracy is the metric at eval steps\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Set some initial parameters\n",
    "batch_size=20\n",
    "args = TrainingArguments(\n",
    "        f\"{modelname}-finetuned-movie-reviews\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Set up a trainer with less data\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=train_small_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Find the best hyperparameters over 10 runs\n",
    "best_run = trainer.hyperparameter_search(n_trials=2, direction=\"maximize\",\n",
    "                                        backend=\"optuna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MYvT5raAyWZ"
   },
   "source": [
    "## Train\n",
    "\n",
    "Now that we have some (hopefully) good hyperparameters, let's train our model on our full training data! This may take some time, so look over the reflection questions in the meantime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAtDWIAqAyWZ"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(modelname,\n",
    "                                                            num_labels=2).to(device)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPoCrMCHAyWZ"
   },
   "source": [
    "## Test\n",
    "\n",
    "Now that we've trained our model, we need to see if it's any good. Let's evaluate it on test data. First we load that data, then we make use of HuggingFace's evaluate library. We are interested in text classification here, so we use that task. In particular, we return the accuracy, precision, recall, and F1-score for our trained model on our test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1oRU3pUhMp"
   },
   "source": [
    "If you ran into memory issues or want to evaluate a model trained for longer on more data, run the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LE_OGLCCUtBI"
   },
   "outputs": [],
   "source": [
    "!gdown 1n6M1LasX02kEe4KYMiNHbbH0-ZIH1Zio\n",
    "!unzip -o distilbert-for-movie-reviews.zip\n",
    "!rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-fTpX4yV4Ei"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-for-movie-reviews\",\n",
    "                                                           num_labels=2).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-for-movie-reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEmeLlrOV-UB"
   },
   "source": [
    "The following gets your test data and returns metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zRs_sBUAyWZ"
   },
   "outputs": [],
   "source": [
    "test_dataset = getDataset(\"sentiment_data/test\", {\"pos\": 0, \"neg\": 1}, tokenizer, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "__WqxyqyAyWZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_evaluator = evaluate.evaluator(\"text-classification\")\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data=test_dataset,\n",
    "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    label_mapping={\"LABEL_0\": 0.0, \"LABEL_1\": 1.0})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzFIBSlHAyWZ"
   },
   "source": [
    "## Save Model\n",
    "\n",
    "Finally, we may want to save our final model. We can do that as below. I also show how we can load our pretrained model for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eigTUlnfAyWZ"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"distilbert-for-movie-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZANYLAX6AyWa"
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-for-movie-reviews\",\n",
    "                                                           num_labels=2).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-for-movie-reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQNh2NB9AyWa"
   },
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ4iWa0cTtZ-"
   },
   "source": [
    "1. [25pts] Below, evaluate a non-finetuned version of DistilBERT on our task. Compare the accuracy of that model with your final model. Reflect on your precision, recall, and F1-score. What is your model doing better or worse at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnvBeIEPT2l8"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1-IhGiHXy7J"
   },
   "source": [
    "2. [10pts] How does the model performance compare to your Naive Bayes' Classifier? What do you think might contribute to the differences between these two models?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jdKH3m8YXW8"
   },
   "source": [
    "[Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d79I5pDzW6QG"
   },
   "source": [
    "3. [5pts] For hyperparameter tuning, what parameters in your model were hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwE5u36rYb1Z"
   },
   "source": [
    "[Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg0nkq2-AyWb"
   },
   "source": [
    "4. [35pts] Run the following code snippet, which evaluates your model on a movie review I wrote. Try out some cases of your own. Does your model work well? Can you come up with cases that trick it?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tyn3oJYYAyWb"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def getScore(review: str, model: AutoModelForSequenceClassification,\n",
    "            tokenizer: AutoTokenizer) -> str:\n",
    "    \"\"\" Returns the label of the movie review\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(\"cpu\")\n",
    "    input_ids = tokenizer(review, return_tensors=\"pt\", padding=True,\n",
    "                          truncation=True)\n",
    "    output = model(**input_ids).logits\n",
    "    pred = np.argmax(output, axis=-1).tolist()[0]\n",
    "    if pred == 0:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "review = \"Sunset Boulevard is an eery movie that deeply upset me. I did love it though.\"\n",
    "getScore(review, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0k3M3VMTAyWX",
    "sohXRw4NAyWY",
    "7MYvT5raAyWZ",
    "uzFIBSlHAyWZ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
